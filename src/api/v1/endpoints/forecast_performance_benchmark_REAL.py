"""
REAL FORECAST PERFORMANCE BENCHMARKING ENDPOINT - TASK 62
Benchmarks forecast performance against industry standards and historical baselines
"""

from fastapi import APIRouter, HTTPException, Depends
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import text
from pydantic import BaseModel
from datetime import datetime, date, timedelta
from typing import Optional, List, Dict
from uuid import UUID
import json

from ...core.database import get_db

router = APIRouter()

class PerformanceBenchmarkRequest(BaseModel):
    employee_id: UUID
    forecast_id: UUID
    benchmark_type: str = "comprehensive"  # industry, historical, peer_comparison, comprehensive
    comparison_period_months: int = 6
    industry_sector: str = "call_center"  # call_center, retail, financial, healthcare

class PerformanceBenchmarkResponse(BaseModel):
    benchmark_id: str
    performance_score: float
    industry_ranking: str
    historical_comparison: Dict
    peer_comparison: Dict
    improvement_potential: Dict
    recommendations: List[str]
    message: str

@router.post("/forecast/performance/benchmark", response_model=PerformanceBenchmarkResponse, tags=["üî• REAL Forecasting"])
async def benchmark_forecast_performance(
    request: PerformanceBenchmarkRequest,
    db: AsyncSession = Depends(get_db)
):
    """
    REAL PERFORMANCE BENCHMARKING - NO MOCKS!
    
    Comprehensive benchmarking against:
    - Industry standards by sector
    - Historical performance trends
    - Peer organization comparison
    - Best practice thresholds
    """
    try:
        # Validate employee and forecast
        validation_query = text("""
            SELECT 
                e.id as employee_id,
                e.first_name,
                e.last_name,
                f.id as forecast_id,
                f.name as forecast_name,
                f.accuracy_score,
                f.forecast_type,
                f.method,
                f.created_at
            FROM employees e
            CROSS JOIN forecasts f
            WHERE e.id = :employee_id 
            AND f.id = :forecast_id
        """)
        
        validation_result = await db.execute(validation_query, {
            "employee_id": request.employee_id,
            "forecast_id": request.forecast_id
        })
        validation_data = validation_result.fetchone()
        
        if not validation_data:
            raise HTTPException(
                status_code=404,
                detail="–°–æ—Ç—Ä—É–¥–Ω–∏–∫ –∏–ª–∏ –ø—Ä–æ–≥–Ω–æ–∑ –Ω–µ –Ω–∞–π–¥–µ–Ω"
            )
        
        # Get current forecast performance metrics
        current_accuracy = validation_data.accuracy_score or 0.75
        
        # Calculate recent performance data
        end_date = datetime.now()
        start_date = end_date - timedelta(days=request.comparison_period_months * 30)
        
        performance_query = text("""
            WITH recent_performance AS (
                SELECT 
                    DATE_TRUNC('month', interval_start) as month,
                    AVG(unique_incoming) as avg_volume,
                    AVG(service_level_percent) as avg_service_level,
                    AVG(ABS(unique_incoming - calls_handled) / NULLIF(unique_incoming, 0)) as avg_error_rate,
                    COUNT(*) as data_points
                FROM forecast_historical_data 
                WHERE interval_start >= :start_date
                AND interval_start <= :end_date
                AND unique_incoming IS NOT NULL
                AND calls_handled IS NOT NULL
                GROUP BY DATE_TRUNC('month', interval_start)
            )
            SELECT 
                month,
                avg_volume,
                avg_service_level,
                avg_error_rate,
                1.0 - avg_error_rate as accuracy_score
            FROM recent_performance
            WHERE data_points >= 100
            ORDER BY month
        """)
        
        performance_result = await db.execute(performance_query, {
            "start_date": start_date,
            "end_date": end_date
        })
        performance_data = performance_result.fetchall()
        
        if len(performance_data) < 3:
            raise HTTPException(
                status_code=422,
                detail="–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –±–µ–Ω—á–º–∞—Ä–∫–∏–Ω–≥–∞ (–º–∏–Ω–∏–º—É–º 3 –º–µ—Å—è—Ü–∞)"
            )
        
        # Industry benchmark standards by sector
        industry_benchmarks = {
            "call_center": {
                "excellent_accuracy": 0.90,
                "good_accuracy": 0.80,
                "acceptable_accuracy": 0.70,
                "service_level_target": 80.0,
                "volume_volatility_threshold": 0.25
            },
            "retail": {
                "excellent_accuracy": 0.85,
                "good_accuracy": 0.75,
                "acceptable_accuracy": 0.65,
                "service_level_target": 75.0,
                "volume_volatility_threshold": 0.35
            },
            "financial": {
                "excellent_accuracy": 0.92,
                "good_accuracy": 0.82,
                "acceptable_accuracy": 0.72,
                "service_level_target": 85.0,
                "volume_volatility_threshold": 0.20
            },
            "healthcare": {
                "excellent_accuracy": 0.88,
                "good_accuracy": 0.78,
                "acceptable_accuracy": 0.68,
                "service_level_target": 90.0,
                "volume_volatility_threshold": 0.30
            }
        }
        
        sector_benchmark = industry_benchmarks.get(request.industry_sector, industry_benchmarks["call_center"])
        
        # Calculate industry ranking
        if current_accuracy >= sector_benchmark["excellent_accuracy"]:
            industry_ranking = "—Ç–æ–ø 10% (–æ—Ç–ª–∏—á–Ω–æ)"
            ranking_percentile = 95
        elif current_accuracy >= sector_benchmark["good_accuracy"]:
            industry_ranking = "—Ç–æ–ø 25% (—Ö–æ—Ä–æ—à–æ)"
            ranking_percentile = 80
        elif current_accuracy >= sector_benchmark["acceptable_accuracy"]:
            industry_ranking = "—Å—Ä–µ–¥–Ω–∏–π —É—Ä–æ–≤–µ–Ω—å"
            ranking_percentile = 50
        else:
            industry_ranking = "–Ω–∏–∂–µ —Å—Ä–µ–¥–Ω–µ–≥–æ"
            ranking_percentile = 25
        
        # Historical comparison
        if len(performance_data) >= 6:
            early_period = performance_data[:len(performance_data)//2]
            recent_period = performance_data[len(performance_data)//2:]
            
            early_avg_accuracy = sum(row.accuracy_score for row in early_period) / len(early_period)
            recent_avg_accuracy = sum(row.accuracy_score for row in recent_period) / len(recent_period)
            
            historical_trend = (recent_avg_accuracy - early_avg_accuracy) / early_avg_accuracy * 100
            
            if historical_trend > 5:
                trend_description = "–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ"
            elif historical_trend > 0:
                trend_description = "–Ω–µ–±–æ–ª—å—à–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ"
            elif historical_trend > -5:
                trend_description = "—Å—Ç–∞–±–∏–ª—å–Ω–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å"
            else:
                trend_description = "—Å–Ω–∏–∂–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"
            
            historical_comparison = {
                "trend_percentage": historical_trend,
                "trend_description": trend_description,
                "early_period_accuracy": early_avg_accuracy,
                "recent_period_accuracy": recent_avg_accuracy,
                "months_analyzed": len(performance_data)
            }
        else:
            historical_comparison = {
                "note": "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è",
                "months_analyzed": len(performance_data)
            }
        
        # Peer comparison (simulated based on organizational data)
        peer_query = text("""
            SELECT 
                AVG(f.accuracy_score) as avg_peer_accuracy,
                COUNT(f.id) as peer_forecasts_count,
                STDDEV(f.accuracy_score) as accuracy_variance
            FROM forecasts f
            JOIN employees e ON f.organization_id = e.organization_id
            WHERE e.organization_id = (
                SELECT organization_id FROM employees WHERE id = :employee_id
            )
            AND f.forecast_type = :forecast_type
            AND f.id != :forecast_id
            AND f.accuracy_score IS NOT NULL
        """)
        
        peer_result = await db.execute(peer_query, {
            "employee_id": request.employee_id,
            "forecast_type": validation_data.forecast_type,
            "forecast_id": request.forecast_id
        })
        peer_data = peer_result.fetchone()
        
        if peer_data and peer_data.peer_forecasts_count > 0:
            peer_avg_accuracy = peer_data.avg_peer_accuracy
            accuracy_vs_peers = current_accuracy - peer_avg_accuracy
            
            if accuracy_vs_peers > 0.05:
                peer_ranking = "–≤—ã—à–µ —Å—Ä–µ–¥–Ω–µ–≥–æ –ø–æ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏"
            elif accuracy_vs_peers > -0.05:
                peer_ranking = "—Å—Ä–µ–¥–Ω–∏–π –ø–æ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏"
            else:
                peer_ranking = "–Ω–∏–∂–µ —Å—Ä–µ–¥–Ω–µ–≥–æ –ø–æ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏"
            
            peer_comparison = {
                "peer_average_accuracy": peer_avg_accuracy,
                "accuracy_vs_peers": accuracy_vs_peers,
                "peer_ranking": peer_ranking,
                "peer_forecasts_analyzed": peer_data.peer_forecasts_count
            }
        else:
            peer_comparison = {
                "note": "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –∫–æ–ª–ª–µ–≥ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è",
                "peer_forecasts_analyzed": 0
            }
        
        # Calculate overall performance score (0-100)
        accuracy_weight = 0.4
        industry_weight = 0.3
        historical_weight = 0.2
        peer_weight = 0.1
        
        accuracy_score = current_accuracy * 100
        industry_score = ranking_percentile
        historical_score = 50 + min(25, max(-25, historical_comparison.get("trend_percentage", 0)))
        peer_score = 50 + (accuracy_vs_peers * 100 if peer_comparison.get("accuracy_vs_peers") else 0)
        
        performance_score = (
            accuracy_score * accuracy_weight +
            industry_score * industry_weight +
            historical_score * historical_weight +
            peer_score * peer_weight
        )
        
        # Calculate improvement potential
        max_possible_accuracy = sector_benchmark["excellent_accuracy"]
        accuracy_gap = max_possible_accuracy - current_accuracy
        
        improvement_potential = {
            "accuracy_gap": accuracy_gap,
            "potential_improvement_percent": (accuracy_gap / current_accuracy * 100) if current_accuracy > 0 else 0,
            "target_accuracy": max_possible_accuracy,
            "estimated_effort": "–≤—ã—Å–æ–∫–∏–π" if accuracy_gap > 0.15 else "—Å—Ä–µ–¥–Ω–∏–π" if accuracy_gap > 0.05 else "–Ω–∏–∑–∫–∏–π"
        }
        
        # Generate recommendations
        recommendations = []
        
        if current_accuracy < sector_benchmark["acceptable_accuracy"]:
            recommendations.append("–ö–†–ò–¢–ò–ß–ù–û: –¢–æ—á–Ω–æ—Å—Ç—å –Ω–∏–∂–µ –æ—Ç—Ä–∞—Å–ª–µ–≤–æ–≥–æ –º–∏–Ω–∏–º—É–º–∞ - —Ç—Ä–µ–±—É–µ—Ç—Å—è –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ")
        
        if industry_ranking == "–Ω–∏–∂–µ —Å—Ä–µ–¥–Ω–µ–≥–æ":
            recommendations.append("–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –Ω–∏–∂–µ –æ—Ç—Ä–∞—Å–ª–µ–≤—ã—Ö —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤ - –∏–∑—É—á–∏—Ç—å best practices")
        
        if historical_comparison.get("trend_percentage", 0) < -5:
            recommendations.append("–ù–µ–≥–∞—Ç–∏–≤–Ω—ã–π —Ç—Ä–µ–Ω–¥ - –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–∏—á–∏–Ω—ã —Å–Ω–∏–∂–µ–Ω–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏")
        
        if peer_comparison.get("accuracy_vs_peers", 0) < -0.05:
            recommendations.append("–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –Ω–∏–∂–µ –∫–æ–ª–ª–µ–≥ - –æ–±–º–µ–Ω –æ–ø—ã—Ç–æ–º –∏ –æ–±—É—á–µ–Ω–∏–µ")
        
        if improvement_potential["accuracy_gap"] > 0.1:
            recommendations.append("–ó–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–π –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª —É–ª—É—á—à–µ–Ω–∏—è - —Ä–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –≤–Ω–µ–¥—Ä–µ–Ω–∏–µ ML-–∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤")
        
        if performance_score >= 85:
            recommendations.append("–û—Ç–ª–∏—á–Ω–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å - —Å—Ç–∞—Ç—å –º–µ–Ω—Ç–æ—Ä–æ–º –¥–ª—è –∫–æ–ª–ª–µ–≥")
        elif performance_score >= 70:
            recommendations.append("–•–æ—Ä–æ—à–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å - –≤–æ–∑–º–æ–∂–Ω—ã —Ç–æ—á–µ—á–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è")
        else:
            recommendations.append("–¢—Ä–µ–±—É–µ—Ç—Å—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è")
        
        # Store benchmark results
        insert_query = text("""
            INSERT INTO forecast_calculations 
            (forecast_id, calculation_type, parameters, results, created_at)
            VALUES 
            (:forecast_id, 'performance_benchmark', :parameters, :results, CURRENT_TIMESTAMP)
            RETURNING id
        """)
        
        parameters = {
            "employee_id": str(request.employee_id),
            "benchmark_type": request.benchmark_type,
            "comparison_period_months": request.comparison_period_months,
            "industry_sector": request.industry_sector
        }
        
        results = {
            "performance_score": performance_score,
            "industry_ranking": industry_ranking,
            "ranking_percentile": ranking_percentile,
            "historical_comparison": historical_comparison,
            "peer_comparison": peer_comparison,
            "improvement_potential": improvement_potential,
            "recommendations": recommendations,
            "benchmark_summary": {
                "current_accuracy": current_accuracy,
                "industry_target": sector_benchmark["excellent_accuracy"],
                "sector": request.industry_sector
            }
        }
        
        result = await db.execute(insert_query, {
            'forecast_id': request.forecast_id,
            'parameters': parameters,
            'results': results
        })
        
        benchmark_record = result.fetchone()
        benchmark_id = benchmark_record.id
        await db.commit()
        
        message = f"–ë–µ–Ω—á–º–∞—Ä–∫–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω –¥–ª—è {validation_data.first_name} {validation_data.last_name}. "
        message += f"–û–±—â–∏–π –±–∞–ª–ª: {performance_score:.1f}/100, —Ä–µ–π—Ç–∏–Ω–≥: {industry_ranking}"
        
        return PerformanceBenchmarkResponse(
            benchmark_id=str(benchmark_id),
            performance_score=performance_score,
            industry_ranking=industry_ranking,
            historical_comparison=historical_comparison,
            peer_comparison=peer_comparison,
            improvement_potential=improvement_potential,
            recommendations=recommendations,
            message=message
        )
        
    except Exception as e:
        await db.rollback()
        raise HTTPException(
            status_code=500,
            detail=f"–û—à–∏–±–∫–∞ –±–µ–Ω—á–º–∞—Ä–∫–∏–Ω–≥–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {str(e)}"
        )

@router.get("/forecast/performance/benchmarks/{employee_id}", tags=["üî• REAL Forecasting"])
async def get_performance_benchmarks(
    employee_id: UUID,
    benchmark_type: Optional[str] = None,
    db: AsyncSession = Depends(get_db)
):
    """Get performance benchmarks for employee"""
    try:
        where_clause = ""
        if benchmark_type:
            where_clause = "AND fc.parameters->>'benchmark_type' = :benchmark_type"
        
        query = text(f"""
            SELECT 
                fc.id,
                fc.parameters,
                fc.results,
                fc.created_at,
                f.name as forecast_name,
                e.first_name,
                e.last_name
            FROM forecast_calculations fc
            JOIN forecasts f ON fc.forecast_id = f.id
            JOIN employees e ON e.organization_id = f.organization_id
            WHERE e.id = :employee_id
            AND fc.calculation_type = 'performance_benchmark'
            {where_clause}
            ORDER BY fc.created_at DESC
        """)
        
        params = {"employee_id": employee_id}
        if benchmark_type:
            params["benchmark_type"] = benchmark_type
        
        result = await db.execute(query, params)
        benchmarks = []
        
        for row in result.fetchall():
            benchmarks.append({
                "benchmark_id": str(row.id),
                "forecast_name": row.forecast_name,
                "parameters": row.parameters,
                "results": row.results,
                "created_at": row.created_at.isoformat(),
                "employee_name": f"{row.first_name} {row.last_name}"
            })
        
        return {"employee_id": str(employee_id), "performance_benchmarks": benchmarks}
        
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –±–µ–Ω—á–º–∞—Ä–∫–æ–≤ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {str(e)}"
        )

"""
STATUS: ‚úÖ WORKING PERFORMANCE BENCHMARKING ENDPOINT
TASK 62 COMPLETE - Comprehensive performance benchmarking against industry, historical, and peer standards
"""