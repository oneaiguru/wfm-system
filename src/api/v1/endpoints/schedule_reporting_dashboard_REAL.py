"""
REAL SCHEDULE REPORTING DASHBOARD ENDPOINT
Task 43/50: Comprehensive Schedule Reporting and Dashboard Data
"""

from fastapi import APIRouter, HTTPException, Depends
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import text
from pydantic import BaseModel
from datetime import datetime, date, timedelta
from typing import Optional, List, Dict, Any
from uuid import UUID
import uuid
import json

from ...core.database import get_db

router = APIRouter()

class DashboardRequest(BaseModel):
    dashboard_scope: str = "–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è"  # –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è, –æ—Ç–¥–µ–ª, –º–µ–Ω–µ–¥–∂–µ—Ä
    scope_id: Optional[UUID] = None
    report_period: str = "—Ç–µ–∫—É—â–∞—è_–Ω–µ–¥–µ–ª—è"  # —Ç–µ–∫—É—â–∞—è_–Ω–µ–¥–µ–ª—è, —Ç–µ–∫—É—â–∏–π_–º–µ—Å—è—Ü, –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã–π
    custom_start: Optional[date] = None
    custom_end: Optional[date] = None

class DashboardResponse(BaseModel):
    dashboard_id: str
    summary_cards: Dict[str, Any]
    charts_data: Dict[str, Any]
    tables_data: Dict[str, Any]
    alerts: List[Dict[str, Any]]
    last_updated: str
    message: str

@router.post("/schedules/reporting/dashboard", response_model=DashboardResponse, tags=["üî• REAL Schedule Reporting"])
async def generate_schedule_dashboard(
    request: DashboardRequest,
    db: AsyncSession = Depends(get_db)
):
    """REAL SCHEDULE DASHBOARD - NO MOCKS! Generates comprehensive dashboard data"""
    try:
        # Determine report period
        if request.report_period == "—Ç–µ–∫—É—â–∞—è_–Ω–µ–¥–µ–ª—è":
            today = date.today()
            start_date = today - timedelta(days=today.weekday())
            end_date = start_date + timedelta(days=6)
        elif request.report_period == "—Ç–µ–∫—É—â–∏–π_–º–µ—Å—è—Ü":
            today = date.today()
            start_date = today.replace(day=1)
            end_date = (start_date + timedelta(days=32)).replace(day=1) - timedelta(days=1)
        else:
            start_date = request.custom_start or date.today()
            end_date = request.custom_end or date.today()
        
        # Build scope conditions
        scope_conditions = []
        params = {"start_date": start_date, "end_date": end_date}
        
        if request.dashboard_scope == "–æ—Ç–¥–µ–ª" and request.scope_id:
            scope_conditions.append("e.department_id = :scope_id")
            params["scope_id"] = request.scope_id
        elif request.dashboard_scope == "–º–µ–Ω–µ–¥–∂–µ—Ä" and request.scope_id:
            scope_conditions.append("e.manager_id = :scope_id")
            params["scope_id"] = request.scope_id
        
        where_clause = "WHERE " + " AND ".join([
            "ws.effective_date <= :end_date",
            "(ws.expiry_date IS NULL OR ws.expiry_date >= :start_date)"
        ] + scope_conditions) if scope_conditions else "WHERE ws.effective_date <= :end_date AND (ws.expiry_date IS NULL OR ws.expiry_date >= :start_date)"
        
        # Summary metrics query
        summary_query = text(f"""
            SELECT 
                COUNT(DISTINCT ws.id) as total_schedules,
                COUNT(DISTINCT ws.employee_id) as total_employees,
                COUNT(DISTINCT e.department_id) as total_departments,
                SUM(ws.total_hours) as total_hours,
                AVG(ws.total_hours) as avg_hours_per_schedule,
                COUNT(CASE WHEN ws.status = 'active' THEN 1 END) as active_schedules,
                COUNT(CASE WHEN ws.status = 'pending' THEN 1 END) as pending_schedules,
                COUNT(CASE WHEN ws.status = 'completed' THEN 1 END) as completed_schedules,
                AVG(ws.optimization_score) as avg_optimization_score
            FROM work_schedules_core ws
            JOIN employees e ON ws.employee_id = e.id
            {where_clause}
        """)
        
        summary_result = await db.execute(summary_query, params)
        summary_row = summary_result.fetchone()
        
        # Department breakdown
        dept_query = text(f"""
            SELECT 
                os.department_name,
                COUNT(ws.id) as schedule_count,
                SUM(ws.total_hours) as total_hours,
                COUNT(DISTINCT ws.employee_id) as employee_count,
                AVG(ws.optimization_score) as avg_score
            FROM work_schedules_core ws
            JOIN employees e ON ws.employee_id = e.id
            JOIN organizational_structure os ON e.department_id = os.id
            {where_clause}
            GROUP BY os.id, os.department_name
            ORDER BY schedule_count DESC
            LIMIT 10
        """)
        
        dept_result = await db.execute(dept_query, params)
        dept_data = dept_result.fetchall()
        
        # Status distribution over time
        daily_query = text(f"""
            SELECT 
                DATE(ws.created_at) as creation_date,
                ws.status,
                COUNT(*) as count
            FROM work_schedules_core ws
            JOIN employees e ON ws.employee_id = e.id
            {where_clause}
            AND ws.created_at >= :start_date
            GROUP BY DATE(ws.created_at), ws.status
            ORDER BY creation_date
        """)
        
        daily_result = await db.execute(daily_query, params)
        daily_data = daily_result.fetchall()
        
        # Template usage
        template_query = text(f"""
            SELECT 
                COALESCE(st.template_name, '–ë–µ–∑ —à–∞–±–ª–æ–Ω–∞') as template_name,
                COUNT(ws.id) as usage_count,
                AVG(ws.optimization_score) as avg_score
            FROM work_schedules_core ws
            JOIN employees e ON ws.employee_id = e.id
            LEFT JOIN schedule_templates st ON ws.template_id = st.id
            {where_clause}
            GROUP BY st.id, st.template_name
            ORDER BY usage_count DESC
            LIMIT 5
        """)
        
        template_result = await db.execute(template_query, params)
        template_data = template_result.fetchall()
        
        # Recent conflicts
        conflicts_query = text(f"""
            SELECT 
                cd.id,
                cd.scope_type,
                cd.conflict_summary,
                cd.created_at
            FROM conflict_detections cd
            WHERE cd.created_at >= :start_date
            ORDER BY cd.created_at DESC
            LIMIT 5
        """)
        
        conflicts_result = await db.execute(conflicts_query, params)
        conflicts_data = conflicts_result.fetchall()
        
        # Build summary cards
        summary_cards = {
            "–æ–±—â–∞—è_—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞": {
                "–≤—Å–µ–≥–æ_—Ä–∞—Å–ø–∏—Å–∞–Ω–∏–π": summary_row.total_schedules or 0,
                "–∑–∞–¥–µ–π—Å—Ç–≤–æ–≤–∞–Ω–æ_—Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤": summary_row.total_employees or 0,
                "–æ—Ö–≤–∞—á–µ–Ω–Ω—ã—Ö_–æ—Ç–¥–µ–ª–æ–≤": summary_row.total_departments or 0,
                "–æ–±—â–∏–µ_—á–∞—Å—ã": summary_row.total_hours or 0
            },
            "—Å—Ç–∞—Ç—É—Å—ã_—Ä–∞—Å–ø–∏—Å–∞–Ω–∏–π": {
                "–∞–∫—Ç–∏–≤–Ω—ã–µ": summary_row.active_schedules or 0,
                "–æ–∂–∏–¥–∞—é—â–∏–µ": summary_row.pending_schedules or 0,
                "–∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–µ": summary_row.completed_schedules or 0
            },
            "–ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏_–∫–∞—á–µ—Å—Ç–≤–∞": {
                "—Å—Ä–µ–¥–Ω–∏–π_–±–∞–ª–ª_–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏": round(summary_row.avg_optimization_score or 0, 2),
                "—Å—Ä–µ–¥–Ω–∏–µ_—á–∞—Å—ã_–Ω–∞_—Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ": round(summary_row.avg_hours_per_schedule or 0, 1),
                "–ø—Ä–æ—Ü–µ–Ω—Ç_–∞–∫—Ç–∏–≤–Ω—ã—Ö": round((summary_row.active_schedules or 0) / max(summary_row.total_schedules or 1, 1) * 100, 1)
            },
            "–ø–µ—Ä–∏–æ–¥_–æ—Ç—á–µ—Ç–∞": {
                "–Ω–∞—á–∞–ª–æ": start_date.isoformat(),
                "–∫–æ–Ω–µ—Ü": end_date.isoformat(),
                "–¥–Ω–µ–π": (end_date - start_date).days + 1
            }
        }
        
        # Build charts data
        charts_data = {
            "—Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ_–ø–æ_–æ—Ç–¥–µ–ª–∞–º": [
                {
                    "–æ—Ç–¥–µ–ª": row.department_name,
                    "—Ä–∞—Å–ø–∏—Å–∞–Ω–∏–π": row.schedule_count,
                    "—á–∞—Å—ã": row.total_hours or 0,
                    "—Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∏": row.employee_count,
                    "—Å—Ä–µ–¥–Ω–∏–π_–±–∞–ª–ª": round(row.avg_score or 0, 2)
                } for row in dept_data
            ],
            "–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ_—à–∞–±–ª–æ–Ω–æ–≤": [
                {
                    "—à–∞–±–ª–æ–Ω": row.template_name,
                    "–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–π": row.usage_count,
                    "—Å—Ä–µ–¥–Ω–∏–π_–±–∞–ª–ª": round(row.avg_score or 0, 2)
                } for row in template_data
            ],
            "–¥–∏–Ω–∞–º–∏–∫–∞_—Å–æ–∑–¥–∞–Ω–∏—è": []
        }
        
        # Process daily data for time series
        daily_grouped = {}
        for row in daily_data:
            date_str = row.creation_date.isoformat()
            if date_str not in daily_grouped:
                daily_grouped[date_str] = {"–¥–∞—Ç–∞": date_str, "–∞–∫—Ç–∏–≤–Ω—ã–µ": 0, "–æ–∂–∏–¥–∞—é—â–∏–µ": 0, "–∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–µ": 0}
            
            daily_grouped[date_str][row.status] = row.count
        
        charts_data["–¥–∏–Ω–∞–º–∏–∫–∞_—Å–æ–∑–¥–∞–Ω–∏—è"] = list(daily_grouped.values())
        
        # Build tables data
        top_employees_query = text(f"""
            SELECT 
                e.first_name, e.last_name,
                COUNT(ws.id) as schedule_count,
                SUM(ws.total_hours) as total_hours,
                AVG(ws.optimization_score) as avg_score
            FROM work_schedules_core ws
            JOIN employees e ON ws.employee_id = e.id
            {where_clause}
            GROUP BY e.id, e.first_name, e.last_name
            ORDER BY schedule_count DESC
            LIMIT 10
        """)
        
        top_employees_result = await db.execute(top_employees_query, params)
        top_employees_data = top_employees_result.fetchall()
        
        tables_data = {
            "—Ç–æ–ø_—Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∏_–ø–æ_—Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è–º": [
                {
                    "—Å–æ—Ç—Ä—É–¥–Ω–∏–∫": f"{row.first_name} {row.last_name}",
                    "–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ_—Ä–∞—Å–ø–∏—Å–∞–Ω–∏–π": row.schedule_count,
                    "–æ–±—â–∏–µ_—á–∞—Å—ã": row.total_hours or 0,
                    "—Å—Ä–µ–¥–Ω–∏–π_–±–∞–ª–ª": round(row.avg_score or 0, 2)
                } for row in top_employees_data
            ],
            "–æ—Ç–¥–µ–ª—ã_–¥–µ—Ç–∞–ª—å–Ω–æ": charts_data["—Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ_–ø–æ_–æ—Ç–¥–µ–ª–∞–º"]
        }
        
        # Generate alerts
        alerts = []
        
        # Low optimization score alert
        if (summary_row.avg_optimization_score or 0) < 70:
            alerts.append({
                "—Ç–∏–ø": "–Ω–∏–∑–∫–∞—è_–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è",
                "—Å–µ—Ä—å–µ–∑–Ω–æ—Å—Ç—å": "—Å—Ä–µ–¥–Ω—è—è",
                "—Å–æ–æ–±—â–µ–Ω–∏–µ": f"–°—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ {summary_row.avg_optimization_score:.1f} –Ω–∏–∂–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º–æ–≥–æ —É—Ä–æ–≤–Ω—è 70",
                "—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è": "–†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –ø–µ—Ä–µ—Å–º–æ—Ç—Ä —à–∞–±–ª–æ–Ω–æ–≤ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–π"
            })
        
        # High pending schedules alert
        pending_ratio = (summary_row.pending_schedules or 0) / max(summary_row.total_schedules or 1, 1)
        if pending_ratio > 0.3:
            alerts.append({
                "—Ç–∏–ø": "–º–Ω–æ–≥–æ_–æ–∂–∏–¥–∞—é—â–∏—Ö_—Ä–∞—Å–ø–∏—Å–∞–Ω–∏–π",
                "—Å–µ—Ä—å–µ–∑–Ω–æ—Å—Ç—å": "–≤—ã—Å–æ–∫–∞—è",
                "—Å–æ–æ–±—â–µ–Ω–∏–µ": f"{summary_row.pending_schedules} —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–π –æ–∂–∏–¥–∞—é—Ç —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è ({pending_ratio*100:.1f}%)",
                "—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è": "–£—Å–∫–æ—Ä—å—Ç–µ –ø—Ä–æ—Ü–µ—Å—Å —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–π"
            })
        
        # Recent conflicts alert
        if len(conflicts_data) > 2:
            recent_conflicts = sum(len(json.loads(c.conflict_summary).get("–∫–æ–Ω—Ñ–ª–∏–∫—Ç—ã", [])) if c.conflict_summary else 0 for c in conflicts_data)
            alerts.append({
                "—Ç–∏–ø": "–æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã_–∫–æ–Ω—Ñ–ª–∏–∫—Ç—ã",
                "—Å–µ—Ä—å–µ–∑–Ω–æ—Å—Ç—å": "—Å—Ä–µ–¥–Ω—è—è",
                "—Å–æ–æ–±—â–µ–Ω–∏–µ": f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {recent_conflicts} –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤ –≤ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è—Ö –∑–∞ –ø–µ—Ä–∏–æ–¥",
                "—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è": "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∏ —É—Å—Ç—Ä–∞–Ω–∏—Ç–µ –∫–æ–Ω—Ñ–ª–∏–∫—Ç—ã —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–π"
            })
        
        if not alerts:
            alerts.append({
                "—Ç–∏–ø": "–≤—Å–µ_–≤_–ø–æ—Ä—è–¥–∫–µ",
                "—Å–µ—Ä—å–µ–∑–Ω–æ—Å—Ç—å": "–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è",
                "—Å–æ–æ–±—â–µ–Ω–∏–µ": "–í—Å–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –Ω–æ—Ä–º—ã",
                "—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è": "–ü—Ä–æ–¥–æ–ª–∂–∞–π—Ç–µ —Ç–µ–∫—É—â—É—é —Ä–∞–±–æ—Ç—É"
            })
        
        # Store dashboard data
        dashboard_id = str(uuid.uuid4())
        current_time = datetime.utcnow()
        
        dashboard_record_query = text("""
            INSERT INTO dashboard_reports 
            (id, dashboard_scope, scope_id, report_period_start, report_period_end,
             summary_cards, charts_data, tables_data, alerts, created_at)
            VALUES 
            (:id, :scope, :scope_id, :start_date, :end_date,
             :summary, :charts, :tables, :alerts, :created_at)
        """)
        
        await db.execute(dashboard_record_query, {
            'id': dashboard_id,
            'scope': request.dashboard_scope,
            'scope_id': request.scope_id,
            'start_date': start_date,
            'end_date': end_date,
            'summary': json.dumps(summary_cards),
            'charts': json.dumps(charts_data),
            'tables': json.dumps(tables_data),
            'alerts': json.dumps(alerts),
            'created_at': current_time
        })
        
        await db.commit()
        
        return DashboardResponse(
            dashboard_id=dashboard_id,
            summary_cards=summary_cards,
            charts_data=charts_data,
            tables_data=tables_data,
            alerts=alerts,
            last_updated=current_time.isoformat(),
            message=f"–î–∞—à–±–æ—Ä–¥ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω –¥–ª—è –æ–±–ª–∞—Å—Ç–∏ '{request.dashboard_scope}' –∑–∞ –ø–µ—Ä–∏–æ–¥ {start_date} - {end_date}. –í—Å–µ–≥–æ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–π: {summary_row.total_schedules}, —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤: {summary_row.total_employees}"
        )
        
    except Exception as e:
        await db.rollback()
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –¥–∞—à–±–æ—Ä–¥–∞: {str(e)}")