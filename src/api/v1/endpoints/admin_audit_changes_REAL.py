"""
Task 49: GET /api/v1/admin/audit/changes
BDD Scenario: "Track System Changes via Audit Log"
Implementation: Audit trail from system_audit_log
Database: system_audit_log, change_tracking

CRITICAL: NO MOCK DATA - Real PostgreSQL queries to wfm_enterprise database
"""

from fastapi import APIRouter, HTTPException, Query
from pydantic import BaseModel
from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta
import psycopg2
import psycopg2.extras
import os
import json

router = APIRouter()

class AuditLogEntry(BaseModel):
    audit_id: str
    event_timestamp: datetime
    user_id: str
    username: str
    action_type: str
    resource_type: str
    resource_id: str
    old_values: Optional[Dict[str, Any]]
    new_values: Optional[Dict[str, Any]]
    change_description: str
    ip_address: str
    user_agent: str
    session_id: str
    severity_level: str
    success: bool
    error_message: Optional[str]

class ChangeTrackingEntry(BaseModel):
    change_id: str
    change_timestamp: datetime
    change_type: str
    table_name: str
    record_id: str
    field_changes: Dict[str, Dict[str, Any]]
    changed_by: str
    change_reason: str
    rollback_available: bool

class AuditChangesResponse(BaseModel):
    status: str
    total_entries: int
    audit_logs: List[AuditLogEntry]
    change_tracking: List[ChangeTrackingEntry]
    summary_stats: Dict[str, Any]
    timestamp: datetime

# Real PostgreSQL Database Connection
def get_database_connection():
    """
    REAL DATABASE CONNECTION to wfm_enterprise
    NO MOCK DATA - connects to actual PostgreSQL instance
    """
    try:
        conn = psycopg2.connect(
            host=os.getenv("DB_HOST", "localhost"),
            database=os.getenv("DB_NAME", "wfm_enterprise"),
            user=os.getenv("DB_USER", "wfm_admin"),
            password=os.getenv("DB_PASSWORD", "wfm_password"),
            port=os.getenv("DB_PORT", "5432")
        )
        return conn
    except psycopg2.Error as e:
        raise HTTPException(status_code=500, detail=f"Database connection failed: {str(e)}")

@router.get("/api/v1/admin/audit/changes", response_model=AuditChangesResponse, tags=["ðŸ”§ System Administration"])
async def get_audit_changes(
    start_date: Optional[datetime] = Query(None, description="Start date for audit log filter"),
    end_date: Optional[datetime] = Query(None, description="End date for audit log filter"),
    user_id: Optional[str] = Query(None, description="Filter by user ID"),
    action_type: Optional[str] = Query(None, description="Filter by action type"),
    resource_type: Optional[str] = Query(None, description="Filter by resource type"),
    severity_level: Optional[str] = Query(None, description="Filter by severity level"),
    include_successful_only: bool = Query(False, description="Include only successful operations"),
    limit: int = Query(100, description="Maximum number of entries to return")
):
    """
    BDD Scenario: "Track System Changes via Audit Log"
    
    Retrieves comprehensive system change audit trail from the wfm_enterprise database.
    Implements real audit logging and change tracking as specified in 
    18-system-administration-configuration.feature scenarios.
    
    REAL DATABASE IMPLEMENTATION:
    - Queries system_audit_log and change_tracking tables directly
    - Provides detailed change history with rollback capability
    - Implements security compliance audit trails
    - Real-time change monitoring and tracking
    """
    
    try:
        conn = get_database_connection()
        cursor = conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor)
        
        # Build audit log query with filters
        audit_filters = ["1=1"]
        audit_params = []
        
        # Default to last 7 days if no date range specified
        if not start_date and not end_date:
            start_date = datetime.now() - timedelta(days=7)
        
        if start_date:
            audit_filters.append("sal.event_timestamp >= %s")
            audit_params.append(start_date)
        
        if end_date:
            audit_filters.append("sal.event_timestamp <= %s")
            audit_params.append(end_date)
        
        if user_id:
            audit_filters.append("sal.user_id = %s")
            audit_params.append(user_id)
        
        if action_type:
            audit_filters.append("sal.action_type = %s")
            audit_params.append(action_type)
        
        if resource_type:
            audit_filters.append("sal.resource_type = %s")
            audit_params.append(resource_type)
        
        if severity_level:
            audit_filters.append("sal.severity_level = %s")
            audit_params.append(severity_level)
        
        if include_successful_only:
            audit_filters.append("sal.success = TRUE")
        
        # Query audit logs with user information
        audit_query = f"""
        SELECT 
            sal.audit_id,
            sal.event_timestamp,
            sal.user_id,
            u.username,
            sal.action_type,
            sal.resource_type,
            sal.resource_id,
            sal.old_values,
            sal.new_values,
            sal.change_description,
            sal.ip_address,
            sal.user_agent,
            sal.session_id,
            sal.severity_level,
            sal.success,
            sal.error_message
        FROM system_audit_log sal
        LEFT JOIN users u ON sal.user_id = u.user_id
        WHERE {' AND '.join(audit_filters)}
        ORDER BY sal.event_timestamp DESC
        LIMIT %s
        """
        
        audit_params.append(limit)
        cursor.execute(audit_query, audit_params)
        audit_rows = cursor.fetchall()
        
        # Query change tracking entries
        change_tracking_query = f"""
        SELECT 
            ct.change_id,
            ct.change_timestamp,
            ct.change_type,
            ct.table_name,
            ct.record_id,
            ct.field_changes,
            ct.changed_by,
            ct.change_reason,
            ct.rollback_available
        FROM change_tracking ct
        WHERE ct.change_timestamp >= %s
        AND ct.change_timestamp <= %s
        ORDER BY ct.change_timestamp DESC
        LIMIT %s
        """
        
        change_start = start_date if start_date else datetime.now() - timedelta(days=7)
        change_end = end_date if end_date else datetime.now()
        
        cursor.execute(change_tracking_query, [change_start, change_end, limit])
        change_rows = cursor.fetchall()
        
        # Process audit log entries
        audit_logs = []
        for row in audit_rows:
            # Parse JSON fields safely
            old_values = None
            new_values = None
            
            try:
                if row['old_values']:
                    old_values = json.loads(row['old_values']) if isinstance(row['old_values'], str) else row['old_values']
                if row['new_values']:
                    new_values = json.loads(row['new_values']) if isinstance(row['new_values'], str) else row['new_values']
            except json.JSONDecodeError:
                # Handle malformed JSON gracefully
                pass
            
            audit_entry = AuditLogEntry(
                audit_id=row['audit_id'],
                event_timestamp=row['event_timestamp'],
                user_id=row['user_id'],
                username=row['username'] or 'Unknown User',
                action_type=row['action_type'],
                resource_type=row['resource_type'],
                resource_id=row['resource_id'],
                old_values=old_values,
                new_values=new_values,
                change_description=row['change_description'],
                ip_address=row['ip_address'],
                user_agent=row['user_agent'] or '',
                session_id=row['session_id'] or '',
                severity_level=row['severity_level'],
                success=row['success'],
                error_message=row['error_message']
            )
            audit_logs.append(audit_entry)
        
        # Process change tracking entries
        change_tracking = []
        for row in change_rows:
            # Parse field changes JSON
            field_changes = {}
            try:
                if row['field_changes']:
                    field_changes = json.loads(row['field_changes']) if isinstance(row['field_changes'], str) else row['field_changes']
            except json.JSONDecodeError:
                field_changes = {}
            
            change_entry = ChangeTrackingEntry(
                change_id=row['change_id'],
                change_timestamp=row['change_timestamp'],
                change_type=row['change_type'],
                table_name=row['table_name'],
                record_id=row['record_id'],
                field_changes=field_changes,
                changed_by=row['changed_by'],
                change_reason=row['change_reason'],
                rollback_available=row['rollback_available']
            )
            change_tracking.append(change_entry)
        
        # Generate summary statistics
        cursor.execute("""
        SELECT 
            action_type,
            COUNT(*) as count,
            SUM(CASE WHEN success = TRUE THEN 1 ELSE 0 END) as successful_count,
            SUM(CASE WHEN success = FALSE THEN 1 ELSE 0 END) as failed_count
        FROM system_audit_log
        WHERE event_timestamp >= %s AND event_timestamp <= %s
        GROUP BY action_type
        ORDER BY count DESC
        """, [change_start, change_end])
        
        stats_rows = cursor.fetchall()
        action_stats = {}
        for stat_row in stats_rows:
            action_stats[stat_row['action_type']] = {
                'total': stat_row['count'],
                'successful': stat_row['successful_count'],
                'failed': stat_row['failed_count']
            }
        
        # Get unique users and resources
        cursor.execute("""
        SELECT 
            COUNT(DISTINCT user_id) as unique_users,
            COUNT(DISTINCT resource_type) as unique_resource_types,
            COUNT(DISTINCT CAST(event_timestamp::DATE AS TEXT)) as active_days
        FROM system_audit_log
        WHERE event_timestamp >= %s AND event_timestamp <= %s
        """, [change_start, change_end])
        
        summary_row = cursor.fetchone()
        
        summary_stats = {
            'action_breakdown': action_stats,
            'unique_users': summary_row['unique_users'],
            'unique_resource_types': summary_row['unique_resource_types'],
            'active_days': summary_row['active_days'],
            'date_range': {
                'start': change_start.isoformat(),
                'end': change_end.isoformat()
            }
        }
        
        cursor.close()
        conn.close()
        
        return AuditChangesResponse(
            status="success",
            total_entries=len(audit_logs) + len(change_tracking),
            audit_logs=audit_logs,
            change_tracking=change_tracking,
            summary_stats=summary_stats,
            timestamp=datetime.now()
        )
        
    except psycopg2.Error as e:
        raise HTTPException(status_code=500, detail=f"Database query failed: {str(e)}")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Audit log retrieval failed: {str(e)}")

@router.get("/api/v1/admin/audit/changes/health", tags=["ðŸ”§ System Administration"])
async def audit_changes_health_check():
    """Health check for audit changes endpoint"""
    
    try:
        conn = get_database_connection()
        cursor = conn.cursor()
        
        # Verify audit tables exist and are accessible
        cursor.execute("""
        SELECT 
            (SELECT COUNT(*) FROM system_audit_log) as total_audit_entries,
            (SELECT COUNT(*) FROM system_audit_log WHERE event_timestamp > NOW() - INTERVAL '24 hours') as recent_entries,
            (SELECT COUNT(*) FROM change_tracking) as total_change_entries,
            (SELECT COUNT(DISTINCT user_id) FROM system_audit_log) as unique_audited_users,
            (SELECT COUNT(DISTINCT action_type) FROM system_audit_log) as unique_action_types
        """)
        
        result = cursor.fetchone()
        cursor.close()
        conn.close()
        
        return {
            "status": "healthy",
            "endpoint": "GET /api/v1/admin/audit/changes",
            "bdd_scenario": "Track System Changes via Audit Log",
            "database_connection": "âœ… Connected to wfm_enterprise",
            "table_validation": "âœ… system_audit_log and change_tracking tables accessible",
            "audit_statistics": {
                "total_audit_entries": result[0],
                "recent_entries_24h": result[1],
                "total_change_entries": result[2],
                "unique_audited_users": result[3],
                "unique_action_types": result[4]
            },
            "features": [
                "Real PostgreSQL audit queries",
                "Comprehensive change tracking",
                "JSON field parsing for old/new values",
                "Security compliance audit trails",
                "Rollback capability tracking",
                "Summary statistics generation"
            ],
            "no_mock_data": True,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        return {
            "status": "unhealthy",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

"""
IMPLEMENTATION NOTES:
âœ… Task 49 Complete: GET /api/v1/admin/audit/changes
âœ… BDD Scenario: "Track System Changes via Audit Log"
âœ… Real PostgreSQL queries to system_audit_log and change_tracking tables
âœ… NO MOCK DATA - actual database integration
âœ… Comprehensive audit trail with user tracking
âœ… Change tracking with rollback capability
âœ… JSON field parsing for old/new values
âœ… Security compliance features and summary statistics

REAL DATABASE FEATURES:
- Direct connection to wfm_enterprise PostgreSQL database
- Queries system_audit_log and change_tracking tables
- Real-time audit log filtering by multiple criteria
- JSON parsing for complex change data structures
- User activity correlation and summary statistics
- Rollback availability tracking for change management
- Security compliance audit trail generation
"""