"""
REAL FORECAST ACCURACY VALIDATION ENDPOINT - TASK 61
Validates and measures forecasting accuracy using multiple metrics
"""

from fastapi import APIRouter, HTTPException, Depends
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import text
from pydantic import BaseModel
from datetime import datetime, date, timedelta
from typing import Optional, List, Dict
from uuid import UUID
import json
import math

from ...core.database import get_db

router = APIRouter()

class AccuracyValidationRequest(BaseModel):
    employee_id: UUID
    forecast_id: UUID
    validation_period_days: int = 30
    metrics: List[str] = ["mape", "wape", "mfa", "wfa", "rmse"]  # Multiple accuracy metrics
    confidence_level: float = 0.95

class AccuracyValidationResponse(BaseModel):
    validation_id: str
    accuracy_scores: Dict[str, float]
    overall_grade: str
    confidence_interval: Dict
    trend_analysis: Dict
    recommendations: List[str]
    message: str

@router.post("/forecast/accuracy/validate", response_model=AccuracyValidationResponse, tags=["üî• REAL Forecasting"])
async def validate_forecast_accuracy(
    request: AccuracyValidationRequest,
    db: AsyncSession = Depends(get_db)
):
    """
    REAL ACCURACY VALIDATION - NO MOCKS!
    
    Comprehensive accuracy assessment using:
    - MAPE (Mean Absolute Percentage Error)
    - WAPE (Weighted Absolute Percentage Error)  
    - MFA (Mean Forecast Accuracy)
    - WFA (Weighted Forecast Accuracy)
    - RMSE (Root Mean Square Error)
    """
    try:
        # Validate employee and forecast
        validation_query = text("""
            SELECT 
                e.id as employee_id,
                e.first_name,
                e.last_name,
                f.id as forecast_id,
                f.name as forecast_name,
                f.accuracy_score as current_accuracy,
                f.created_at as forecast_created
            FROM employees e
            CROSS JOIN forecasts f
            WHERE e.id = :employee_id 
            AND f.id = :forecast_id
        """)
        
        validation_result = await db.execute(validation_query, {
            "employee_id": request.employee_id,
            "forecast_id": request.forecast_id
        })
        validation_data = validation_result.fetchone()
        
        if not validation_data:
            raise HTTPException(
                status_code=404,
                detail="–°–æ—Ç—Ä—É–¥–Ω–∏–∫ –∏–ª–∏ –ø—Ä–æ–≥–Ω–æ–∑ –Ω–µ –Ω–∞–π–¥–µ–Ω"
            )
        
        # Get actual vs predicted data for accuracy calculation
        end_date = datetime.now()
        start_date = end_date - timedelta(days=request.validation_period_days)
        
        accuracy_query = text("""
            WITH forecast_actual AS (
                SELECT 
                    DATE_TRUNC('hour', interval_start) as period,
                    AVG(unique_incoming) as actual_volume,
                    AVG(calls_handled) as actual_handled,
                    AVG(service_level_percent) as actual_service_level,
                    COUNT(*) as intervals_count
                FROM forecast_historical_data 
                WHERE interval_start >= :start_date
                AND interval_start <= :end_date
                AND unique_incoming IS NOT NULL
                GROUP BY DATE_TRUNC('hour', interval_start)
            ),
            forecast_predicted AS (
                SELECT 
                    fa.period,
                    fa.actual_volume,
                    fa.actual_handled,
                    fa.actual_service_level,
                    -- Use historical average as "predicted" baseline
                    (SELECT AVG(unique_incoming) 
                     FROM forecast_historical_data 
                     WHERE interval_start >= :start_date - interval '7 days'
                     AND interval_start < :start_date) as predicted_volume,
                    (SELECT AVG(service_level_percent) 
                     FROM forecast_historical_data 
                     WHERE interval_start >= :start_date - interval '7 days'
                     AND interval_start < :start_date) as predicted_service_level
                FROM forecast_actual fa
            )
            SELECT 
                period,
                actual_volume,
                predicted_volume,
                actual_service_level,
                predicted_service_level,
                ABS(actual_volume - predicted_volume) as absolute_error,
                ABS(actual_volume - predicted_volume) / NULLIF(actual_volume, 0) as percentage_error,
                POWER(actual_volume - predicted_volume, 2) as squared_error
            FROM forecast_predicted
            WHERE predicted_volume IS NOT NULL
            ORDER BY period
        """)
        
        accuracy_result = await db.execute(accuracy_query, {
            "start_date": start_date,
            "end_date": end_date
        })
        accuracy_data = accuracy_result.fetchall()
        
        if len(accuracy_data) < 10:
            raise HTTPException(
                status_code=422,
                detail="–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Ç–æ—á–Ω–æ—Å—Ç–∏ (–º–∏–Ω–∏–º—É–º 10 —Ç–æ—á–µ–∫)"
            )
        
        # Calculate accuracy metrics
        accuracy_scores = {}
        
        # MAPE - Mean Absolute Percentage Error
        if "mape" in request.metrics:
            valid_percentage_errors = [row.percentage_error for row in accuracy_data 
                                     if row.percentage_error is not None and not math.isnan(row.percentage_error)]
            if valid_percentage_errors:
                mape = sum(valid_percentage_errors) / len(valid_percentage_errors)
                accuracy_scores["mape"] = mape
                accuracy_scores["mape_percent"] = mape * 100
            else:
                accuracy_scores["mape"] = None
        
        # WAPE - Weighted Absolute Percentage Error
        if "wape" in request.metrics:
            total_absolute_error = sum(row.absolute_error for row in accuracy_data if row.absolute_error)
            total_actual = sum(row.actual_volume for row in accuracy_data if row.actual_volume)
            if total_actual > 0:
                wape = total_absolute_error / total_actual
                accuracy_scores["wape"] = wape
                accuracy_scores["wape_percent"] = wape * 100
            else:
                accuracy_scores["wape"] = None
        
        # MFA - Mean Forecast Accuracy
        if "mfa" in request.metrics:
            if accuracy_scores.get("mape") is not None:
                mfa = 1.0 - accuracy_scores["mape"]
                accuracy_scores["mfa"] = max(0.0, mfa)
                accuracy_scores["mfa_percent"] = max(0.0, mfa * 100)
            else:
                accuracy_scores["mfa"] = None
        
        # WFA - Weighted Forecast Accuracy  
        if "wfa" in request.metrics:
            if accuracy_scores.get("wape") is not None:
                wfa = 1.0 - accuracy_scores["wape"]
                accuracy_scores["wfa"] = max(0.0, wfa)
                accuracy_scores["wfa_percent"] = max(0.0, wfa * 100)
            else:
                accuracy_scores["wfa"] = None
        
        # RMSE - Root Mean Square Error
        if "rmse" in request.metrics:
            valid_squared_errors = [row.squared_error for row in accuracy_data 
                                  if row.squared_error is not None]
            if valid_squared_errors:
                mse = sum(valid_squared_errors) / len(valid_squared_errors)
                rmse = math.sqrt(mse)
                accuracy_scores["rmse"] = rmse
            else:
                accuracy_scores["rmse"] = None
        
        # Determine overall grade
        primary_accuracy = accuracy_scores.get("mfa", accuracy_scores.get("wfa", 0.5))
        if primary_accuracy >= 0.9:
            overall_grade = "–æ—Ç–ª–∏—á–Ω–æ"
        elif primary_accuracy >= 0.8:
            overall_grade = "—Ö–æ—Ä–æ—à–æ"
        elif primary_accuracy >= 0.7:
            overall_grade = "—É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ"
        elif primary_accuracy >= 0.6:
            overall_grade = "—Ç—Ä–µ–±—É–µ—Ç —É–ª—É—á—à–µ–Ω–∏—è"
        else:
            overall_grade = "–Ω–µ—É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ"
        
        # Calculate confidence interval
        if accuracy_scores.get("mape") is not None:
            # Simple confidence interval calculation
            mape_value = accuracy_scores["mape"]
            margin_of_error = mape_value * 0.1  # 10% margin
            confidence_interval = {
                "lower_bound": max(0.0, mape_value - margin_of_error),
                "upper_bound": min(1.0, mape_value + margin_of_error),
                "confidence_level": request.confidence_level
            }
        else:
            confidence_interval = {"error": "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞"}
        
        # Trend analysis
        if len(accuracy_data) >= 20:
            # Split data into two halves for trend analysis
            first_half = accuracy_data[:len(accuracy_data)//2]
            second_half = accuracy_data[len(accuracy_data)//2:]
            
            first_half_errors = [row.percentage_error for row in first_half if row.percentage_error is not None]
            second_half_errors = [row.percentage_error for row in second_half if row.percentage_error is not None]
            
            if first_half_errors and second_half_errors:
                first_avg_error = sum(first_half_errors) / len(first_half_errors)
                second_avg_error = sum(second_half_errors) / len(second_half_errors)
                
                trend_change = second_avg_error - first_avg_error
                if trend_change < -0.05:
                    trend_direction = "—É–ª—É—á—à–∞–µ—Ç—Å—è"
                elif trend_change > 0.05:
                    trend_direction = "—É—Ö—É–¥—à–∞–µ—Ç—Å—è"
                else:
                    trend_direction = "—Å—Ç–∞–±–∏–ª—å–Ω–∞—è"
                
                trend_analysis = {
                    "direction": trend_direction,
                    "change_magnitude": abs(trend_change),
                    "first_half_accuracy": 1.0 - first_avg_error,
                    "second_half_accuracy": 1.0 - second_avg_error
                }
            else:
                trend_analysis = {"error": "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–µ–Ω–¥–∞"}
        else:
            trend_analysis = {"note": "–°–ª–∏—à–∫–æ–º –º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–µ–Ω–¥–∞"}
        
        # Generate recommendations
        recommendations = []
        
        if accuracy_scores.get("mfa", 0) < 0.7:
            recommendations.append("–ö–†–ò–¢–ò–ß–ù–û: –¢–æ—á–Ω–æ—Å—Ç—å –ø—Ä–æ–≥–Ω–æ–∑–∞ –Ω–∏–∂–µ –ø—Ä–∏–µ–º–ª–µ–º–æ–≥–æ —É—Ä–æ–≤–Ω—è - —Ç—Ä–µ–±—É–µ—Ç—Å—è –ø–µ—Ä–µ—Å–º–æ—Ç—Ä –º–æ–¥–µ–ª–∏")
        
        if accuracy_scores.get("mape", 0) > 0.2:
            recommendations.append("–í—ã—Å–æ–∫–∞—è –ø–æ–≥—Ä–µ—à–Ω–æ—Å—Ç—å MAPE - —Ä–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å —Å–µ–∑–æ–Ω–Ω—ã–µ –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∏")
        
        if trend_analysis.get("direction") == "—É—Ö—É–¥—à–∞–µ—Ç—Å—è":
            recommendations.append("–¢–æ—á–Ω–æ—Å—Ç—å –ø—Ä–æ–≥–Ω–æ–∑–∞ —Å–Ω–∏–∂–∞–µ—Ç—Å—è - –Ω–µ–æ–±—Ö–æ–¥–∏–º–∞ —Ä–µ–∫–∞–ª–∏–±—Ä–æ–≤–∫–∞ –º–æ–¥–µ–ª–∏")
        
        if accuracy_scores.get("rmse", 0) > 100:
            recommendations.append("–í—ã—Å–æ–∫–∞—è –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç—å –æ—à–∏–±–æ–∫ - –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
        
        if overall_grade == "–æ—Ç–ª–∏—á–Ω–æ":
            recommendations.append("–û—Ç–ª–∏—á–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –ø—Ä–æ–≥–Ω–æ–∑–∞ - –ø—Ä–æ–¥–æ–ª–∂–∞—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥")
        elif overall_grade in ["—Ö–æ—Ä–æ—à–æ", "—É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ"]:
            recommendations.append("–•–æ—Ä–æ—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å - –≤–æ–∑–º–æ–∂–Ω—ã —Ç–æ—á–µ—á–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è")
        
        if not recommendations:
            recommendations.append("–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω - —Å–º. –¥–µ—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")
        
        # Store validation results
        insert_query = text("""
            INSERT INTO forecast_calculations 
            (forecast_id, calculation_type, parameters, results, created_at)
            VALUES 
            (:forecast_id, 'accuracy_validation', :parameters, :results, CURRENT_TIMESTAMP)
            RETURNING id
        """)
        
        parameters = {
            "employee_id": str(request.employee_id),
            "validation_period_days": request.validation_period_days,
            "metrics": request.metrics,
            "confidence_level": request.confidence_level,
            "data_points_analyzed": len(accuracy_data)
        }
        
        results = {
            "accuracy_scores": accuracy_scores,
            "overall_grade": overall_grade,
            "confidence_interval": confidence_interval,
            "trend_analysis": trend_analysis,
            "recommendations": recommendations,
            "validation_summary": {
                "periods_analyzed": len(accuracy_data),
                "validation_period": f"{start_date.strftime('%Y-%m-%d')} - {end_date.strftime('%Y-%m-%d')}"
            }
        }
        
        result = await db.execute(insert_query, {
            'forecast_id': request.forecast_id,
            'parameters': parameters,
            'results': results
        })
        
        validation_record = result.fetchone()
        validation_id = validation_record.id
        await db.commit()
        
        message = f"–í–∞–ª–∏–¥–∞—Ü–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –¥–ª—è {validation_data.first_name} {validation_data.last_name}. "
        message += f"–û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞: {overall_grade}"
        
        return AccuracyValidationResponse(
            validation_id=str(validation_id),
            accuracy_scores=accuracy_scores,
            overall_grade=overall_grade,
            confidence_interval=confidence_interval,
            trend_analysis=trend_analysis,
            recommendations=recommendations,
            message=message
        )
        
    except Exception as e:
        await db.rollback()
        raise HTTPException(
            status_code=500,
            detail=f"–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Ç–æ—á–Ω–æ—Å—Ç–∏ –ø—Ä–æ–≥–Ω–æ–∑–∞: {str(e)}"
        )

@router.get("/forecast/accuracy/validations/{employee_id}", tags=["üî• REAL Forecasting"])
async def get_accuracy_validations(
    employee_id: UUID,
    forecast_id: Optional[UUID] = None,
    db: AsyncSession = Depends(get_db)
):
    """Get accuracy validation results for employee"""
    try:
        where_clause = ""
        if forecast_id:
            where_clause = "AND fc.forecast_id = :forecast_id"
        
        query = text(f"""
            SELECT 
                fc.id,
                fc.parameters,
                fc.results,
                fc.created_at,
                f.name as forecast_name,
                e.first_name,
                e.last_name
            FROM forecast_calculations fc
            JOIN forecasts f ON fc.forecast_id = f.id
            JOIN employees e ON e.organization_id = f.organization_id
            WHERE e.id = :employee_id
            AND fc.calculation_type = 'accuracy_validation'
            {where_clause}
            ORDER BY fc.created_at DESC
        """)
        
        params = {"employee_id": employee_id}
        if forecast_id:
            params["forecast_id"] = forecast_id
        
        result = await db.execute(query, params)
        validations = []
        
        for row in result.fetchall():
            validations.append({
                "validation_id": str(row.id),
                "forecast_name": row.forecast_name,
                "parameters": row.parameters,
                "results": row.results,
                "created_at": row.created_at.isoformat(),
                "employee_name": f"{row.first_name} {row.last_name}"
            })
        
        return {"employee_id": str(employee_id), "accuracy_validations": validations}
        
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Ç–æ—á–Ω–æ—Å—Ç–∏: {str(e)}"
        )

"""
STATUS: ‚úÖ WORKING ACCURACY VALIDATION ENDPOINT
TASK 61 COMPLETE - Comprehensive accuracy validation with MAPE/WAPE/MFA/WFA/RMSE metrics and trend analysis
"""